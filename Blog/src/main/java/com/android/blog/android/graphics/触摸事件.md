
- 二，触摸事件的起源（Linux）
  - 触摸屏驱动捕获原始事件
    - 信号触发，介绍触摸屏原理
    - 信号转换，模拟信号转为数字信号
  - 驱动上报原始事件
    - Linux input 子系统介绍
    - 驱动与 Linux kernel 建立通信连接
    - 建立成功后，驱动上报原始事件
    - Linux 内核处理/解析事件
- 三，触摸事件的传递（Android）
  - 现在触摸数据已经保存在 /dev/input/xxx 文件了，接下来的任务就是读取节点，再封装成不同的事件类型，屏幕坐标，分发给APP
  - native 层，inputflinger、sf进程
  - java 层，SystemServer进程
    - APP事件的分发顺序
    - viewrootimpl
      - 这个类在之前的几篇文章中反复出现， activitythread 作为 ams 和 app 之间的沟通的桥梁，viewrootimpl 就是 wms 和 app 的中央枢纽，和 view 相关的发/收消息基本上都在这个类
      - 那么问题就来了，事件肯定是先到达 view 的，但我们都知道，在实际的开发过程中，activity/dialog 往往最先得到事件，并且还可以拦截掉，不继续向下分发给视图，这是为什么？
- 四，触摸事件的消费（Application）
  - activity 拦截与消费
    - 每一层都可以消费，并且，可以选择是否要拦截
  - viewgroup 拦截与消费
  - view 拦截与消费
  - 当发生事件冲突时，我们只需要一层层剥开固定的几个方法，非常简单
- 五，结语
  - 总结一下从按下屏幕后，事件是怎么传递到我们的应用的？
  - 首先，触摸屏驱动捕获事件，转交给内核..
  - 最后，一次完整的 Android 触摸事件的分发流程，大致是这样的
- 六，参考资料


### QA

- 触控MCU和触控IC的区别是什么？
  - 触控IC可以理解为IC只负责输出高或低电平的信号，再给后面的 主MCU做采集处理。
  - 触控MCU是指MCU内置了touch单元，相当于SOC，无需外挂触控IC，设计，验证参数整体性能时，可以通过调试工具的GUI，直观监测参数调整后的效果。
  - 而触控IC，则为独立的touch芯片，通常是通过串行接口(例如，I2C、SPI)与主控MCU之间进行通讯实现数据交换，用户需要开发相应的通讯程序，都增加了软件开发的负荷。
- Linux 主动加载设备驱动


### 触摸事件的起源（Linux）

#### 从触摸屏到 CPU（I²C总线）

在[《当我们点击“微信”应用后，它是怎么显示出来的？》](https://mp.weixin.qq.com/s/JeGPyknzc0G_TCQNHZD3AQ)这篇文章中，为了了解什么是 GPU / DPU 模块，我们拆了一台小米11手机

今天，我们继续来拆小米，与上次不同的是，今儿拆的是小米10（因为没找到米11/12的屏幕拆解图。。）

如图

小米10屏幕的触控IC使用的是，来自意法半导体"FJABH"触控芯片方案，这块芯片是用来干嘛的呢？

用来和 CPU 进行通信的

触摸屏 IC 芯片，一方面控制触摸屏面板，另一方面接收来自主设备的 I²C 信号

对于我们开发来说，需要关注的只有跟我们交互的I2C总线，其他并不关心。

I2C 是支持中断

I2C 是硬件层面上，用于通信的协议，我们都知道，Android 使用的是 Linux 作为内核系统来管理硬件设备的

我们都知道，CPU 和触摸屏是两个不同的硬件设备，我们的代码是跑在 CPU 上的，要想得到触摸屏的触摸信号，

今天是为了了解触控 IC

文章的开头，我们需要了解触摸事件是怎么从硬件驱动传递到内核的，这需要 触控 IC 来帮助理解

了解 '触摸屏的信号变化是怎么到达 CPU 的' 这点比较重要，我们再来重复一遍刚刚的流程

内核系统作为一个应用程序，自然可以通过

抛开操作系统不谈

新思 触控 ic S3200

使用 i2c 作为通信协议，

[kernel/drivers/i2c](https://gitlab.com/yibaoshan/firenow-oreo-rk3399/-/tree/master/kernel/drivers/i2c)

好了，只要触摸屏的信号发生变化，触控 IC 芯片就能通过 I²C 总线通知到 CPU 了

第二种I2C驱动是所有的I2C操作都放在驱动层实现，直接向应用层提供最终结果。

应用层甚至不需要知道这里面有I2C存在，譬如电容式触摸屏驱动，直接向应用层提供/dev/input/event1的操作接口

应用层编程的人根本不知道event1中涉及到了I2C。这种是我们后续分析的重点。

触摸屏作为一个输入设备，通过实现 I²C 接口，将自己注册到系统的

据我和电子工程师朋友沟通，大部分触摸屏都是使用 I²C 协议和 SoC 通信的，

下一步，只需要跑在 CPU 上的应用程序 -- 操作系统

这里我们不讨论触摸屏的工作原理

矢量压力传感式、电阻式、电容式、红外线式和表面声波式

我们平时使用的手机几乎都是电容触摸屏，电容触摸屏的工作原理分为：

单个电容

你有没有想过，电容屏的工作原理是怎样的？

我们现在

操作系统来判定，当前是

I²C 通信协议用来规定，什么表示设备开始发送数据了，什么表示结束发送，设备类型是什么，厂家是谁，怎么向 CPU 发送中断请求等等一系列规则

#### 内核对驱动的管理（input 子系统）

和 CPU 建立通信只是第一步，接下来就需要通信双方商量具体的上报规则

以键盘事件举例，同样都是按下 'A' 按键

达尔优键盘上报的是：0010

罗技键盘上报的是：0001

同一个按键，两个键盘厂商上报的数据却不相同，这显然是不行的

为此，

触摸屏事件通过 I²C 传递到 SoC 芯片以后，就可以被操作系统这个大应用程序读取了。

我们都知道，在 Android 系统中，内核部分使用的是 Linux

为了统一管理各种输入设备（键盘、鼠标、触摸屏等），Linux 专门抽象出 input 子系统框架来处理输入消息。

本质上，这些输入设备还是字符设备，只是套上了 input 框架，驱动开发者只需要负责上报按键值、坐标等信息， input 核心层负责处理这些事件，框架如下图

input子系统分为三层：

最下层：输入设备驱动层，drivers/input/xxx

中间层：输入核心层，input.c属于这一层，这里是 Linux 核心逻辑

最上层：输入事件驱动层，evdev.c和mousedev.c和joydev.c属于这一层，对应 /dev/input/xxx

Linux input 对触摸事件进行转化、消除噪声、去抖

触摸屏作为输入设备的其中一种，在图中处于 drivers/硬件设备 层。因此，触摸屏驱动不但要实现上一节提到的 I²C 接口用于通信，还需要实现 input 接口用于上报触摸事件

触控芯片

/dev/input目录下显示的是已经注册在内核中的设备编程接口，用户通过open这些设备文件来打开不同的输入设备进行硬件操作。

设备的注册/连接/上报的过程比较复杂，感兴趣的朋友可以用 'Linux input 子系统开发' 作为关键字，自行搜索相关文章（*推荐韦东山老师的 Linux 嵌入式系列*）

最后我们来总结一下这两小节的内容：按下触摸屏后，电压/电流的变化被传感器捕获，通过模数转换器（ADC）同步到触控芯片，触控芯片再通过 i2c 总线汇报给 CPU。

接着，在 Linux 平台，触控芯片还实现了 input 协议，事件开始按照规定协议上报给内核系统处理

触摸屏某点被按下，产生INT_TC中断；

在中断处理程序中，打开定时器

定时器时间到，启动ADC转换，得到x和y坐标；

ADC结束，产生ADC中断；

、在ADC中断处理函数里，上报（input_event），启

抬起，松开屏幕

到了这里，触摸屏的事件已经能被应用程序读取了，接下来就看框架层（Android Framework）如何使用了

### 触摸事件的传递（Android Framework）

上回书说到，触摸屏上报的事件已经保存到 /dev/input/xxx 设备文件中，那么 Framework 接下来的任务是，读取保存的触摸事件，封装成 MotionEvent / KeyEvent ，再分发给当前正在运行的 APP 使用

可见，在 Android Framework 中，核心逻辑可以分为两个部分，触摸事件的读取和分发

在接下来的文章中，我们将会了解到

这两件事

一来都是业务逻辑，太多了记不过来。二来每次版本升级多少都会有改动，版本之间有差异对 Google 来说非常正常，记得某个版本的实现，意义不大

在 Android Framework 中，inputservice 是负责读取触摸消息的角色

sf 是负责分发事件的角色

看过前两篇的文章或许有疑问，sf不是显示合成的

了解每个类的职责，什么时候通信搞懂几个关键点即可，代码细节可以自己看源码

了解流程为主，简单介绍各个角色的几个关键点

看起来内容并不是很多，但是，framework 还牵扯到 window 体系，几个模块错综复杂

对错综复杂，为了方便理解，我们先站在程序设计的角度

能够被触摸

我是图片

如图，

ims 必须依赖这些底层组件，才能优雅的实现事件的读取与分发

下文 ims 指的是 input，wms 指的是 window，sf 指的是 surface，大致的启动流程：先启动 native 进程（sf），再启动 java 进程（）

let's go

#### 打个招呼

我们都知道，InputManagerService 作为输入设备的枢纽，在系统中起到承上启下的衔接作用。但是，IMS 也不是直接读取，完成读取/分发的另有其人

接下来，我们将一起来认识

EventHub

文件在frameworks/native/services/inputflinger/EventHub.cpp

它的作用是监听、读取/dev/input目录下产生的新事件，并封装成RawEvent结构体供InputReader使用。

InputReader
文件在frameworks/native/services/inputflinger/InputReader.cpp

InputReader运行在一个单独的进程中，这个进程由InputManagerService的初始化而新建，具体内容请见：

### 参考资料

从上到下顺序为：触摸屏原理、I2C总线原理、Input 子系统框架、Framework 框架、应用层 APP

- I2C总线 & Drivers & Linux Input 子系统
- [电阻屏已经被智能手机抛弃，还有哪些应用场景？](https://rohm.eefocus.com/article/id-317)
- [手机全贴合屏幕技术解析](https://blog.csdn.net/weixin_51554164/article/details/124965131)
- [【Linux驱动】I2C子系统与触摸屏驱动 - @hongZ](https://blog.csdn.net/qq_39797956/article/details/118863217)
- [【Linux驱动】input子系统与按键驱动 - @hongZ](https://blog.csdn.net/qq_39797956/article/details/117898095)
- [Linux驱动开发|input子系统 - 安迪西](https://blog.csdn.net/Chuangke_Andy/article/details/122181549)
- [Linux驱动开发|电容触摸屏 - 安迪西](https://blog.csdn.net/Chuangke_Andy/article/details/122454299)
- [Linux裸机开发|电容触摸屏实验 - 安迪西](https://blog.csdn.net/Chuangke_Andy/article/details/120935263)
- [从 0 开始学 Linux 驱动开发 - Hcamael](https://paper.seebug.org/779/)
- [Android(Linux) 输入子系统解析 - Andy Lee](http://huaqianlee.github.io/2017/11/23/Android/Android-Linux-input-system-analysis/)
- [Android 如何上报 Touchevent 给应用层 - 董刚](https://dqdongg.com/c/touch/android/2014/07/10/Touch-inputevent.html)
- Android Framework
- [Android 输入子系统1：IMS 初始化与启动 - 李斌](https://sleticalboy.github.io/android/2021/01/22/android-input-subsystem-1/)
